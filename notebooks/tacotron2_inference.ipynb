{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_tts.processor.ljspeech import LJSpeechProcessor\n",
    "from tensorflow_tts.processor.ljspeech import symbols, _symbol_to_id\n",
    "\n",
    "from tensorflow_tts.configs import Tacotron2Config\n",
    "from tensorflow_tts.models import TFTacotron2\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../examples/tacotron2/conf/tacotron2.v1.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Tacotron2Config(**config[\"tacotron2_params\"])\n",
    "processor = LJSpeechProcessor(None, \"english_cleaners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"i love you so much.\"\n",
    "input_ids = processor.text_to_sequence(input_text)\n",
    "input_ids = np.concatenate([input_ids, [len(symbols) - 1]], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2 = TFTacotron2(config=config, training=False, name=\"tacotron2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2.setup_window(win_front=6, win_back=6)\n",
    "tacotron2.setup_maximum_iterations(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to Pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output, mel_outputs, stop_token_prediction, alignment_history = tacotron2.inference(\n",
    "        input_ids=tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
    "        input_lengths=tf.convert_to_tensor([len(input_ids)], tf.int32),\n",
    "        speaker_ids=tf.convert_to_tensor([0], dtype=tf.int32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2.load_weights(\"../examples/tacotron2/checkpoints/model-100000.h5\", by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model into pb and do inference. Note that signatures should be a tf.function with input_signatures.\n",
    "tf.saved_model.save(tacotron2, \"./test_saved\", signatures=tacotron2.inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2 = tf.saved_model.load(\"./test_saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Unless you work on a ship, it's unlikely that you use the word boatswain in everyday conversation, so it's understandably a tricky one. The word - which refers to a petty officer in charge of hull maintenance is not pronounced boats-wain Rather, it's bo-sun to reflect the salty pronunciation of sailors, as The Free Dictionary explains.\"\n",
    "input_ids = processor.text_to_sequence(input_text)\n",
    "input_ids = np.concatenate([input_ids, [len(symbols) - 1]], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output, mel_outputs, stop_token_prediction, alignment_history = tacotron2.inference(\n",
    "        tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
    "        tf.convert_to_tensor([len(input_ids)], tf.int32),\n",
    "        tf.convert_to_tensor([0], dtype=tf.int32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(f'Alignment steps')\n",
    "im = ax.imshow(\n",
    "    alignment_history[0].numpy(),\n",
    "    aspect='auto',\n",
    "    origin='lower',\n",
    "    interpolation='none')\n",
    "fig.colorbar(im, ax=ax)\n",
    "xlabel = 'Decoder timestep'\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel('Encoder timestep')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_outputs = tf.reshape(mel_outputs, [-1, 80]).numpy()\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.set_title(f'Predicted Mel-after-Spectrogram')\n",
    "im = ax1.imshow(np.rot90(mel_outputs), aspect='auto', interpolation='none')\n",
    "fig.colorbar(mappable=im, shrink=0.65, orientation='horizontal', ax=ax1)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let inference other input to check dynamic shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"The Commission further recommends that the Secret Service coordinate its planning as closely as possible with all of the Federal agencies from which it receives information.\"\n",
    "input_ids = processor.text_to_sequence(input_text)\n",
    "input_ids = np.concatenate([input_ids, [len(symbols) - 1]], -1)  # eos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output, mel_outputs, stop_token_prediction, alignment_history = tacotron2.inference(\n",
    "        tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
    "        tf.convert_to_tensor([len(input_ids)], tf.int32),\n",
    "        tf.convert_to_tensor([0], dtype=tf.int32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(f'Alignment steps')\n",
    "im = ax.imshow(\n",
    "    alignment_history[0].numpy(),\n",
    "    aspect='auto',\n",
    "    origin='lower',\n",
    "    interpolation='none')\n",
    "fig.colorbar(im, ax=ax)\n",
    "xlabel = 'Decoder timestep'\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel('Encoder timestep')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_outputs = tf.reshape(mel_outputs, [-1, 80]).numpy()\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.set_title(f'Predicted Mel-after-Spectrogram')\n",
    "im = ax1.imshow(np.rot90(mel_outputs), aspect='auto', interpolation='none')\n",
    "fig.colorbar(mappable=im, shrink=0.65, orientation='horizontal', ax=ax1)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
