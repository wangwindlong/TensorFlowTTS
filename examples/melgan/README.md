# MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis
Based on the script [`train_melgan.py`](https://github.com/dathudeptrai/TensorflowTTS/blob/melgan-example/examples/melgan/train_melgan.py).

## Training MelGAN from scratch with LJSpeech dataset.
This example code show you how to train MelGAN from scratch with Tensorflow 2 based on custom training loop and tf.function. The data used for this example is LJSpeech, you can download the dataset at  [link](https://keithito.com/LJ-Speech-Dataset/).

### Step 1: Create Tensorflow based Dataloader (tf.dataset)
First, you need define data loader based on AbstractDataset class (see [`abstract_dataset.py`](https://github.com/dathudeptrai/TensorflowTTS/blob/tacotron-2-example/tensorflow_tts/datasets/abstract_dataset.py)). On this example, a dataloader read dataset from path. I use suffix to classify what file is a audio and mel-spectrogram (see [`audio_mel_dataset.py`](https://github.com/dathudeptrai/TensorflowTTS/blob/melgan-example/examples/melgan/audio_mel_dataset.py)). If you already have preprocessed version of your target dataset, you don't need to use this example dataloader, you just need refer my dataloader and modify **generator function** to adapt with your case. Normally, a generator function should return [audio, mel].

### Step 2: Training from scratch
After you redefine your dataloader, pls modify an input arguments, train_dataset and valid_dataset from [`train_melgan.py`](https://github.com/dathudeptrai/TensorflowTTS/blob/melgan-example/examples/melgan/train_melgan.py). Here is an example command line to training tacotron-2 from scratch:

```bash
CUDA_VISIBLE_DEVICES=0 nohup python train_melgan.py \
  --train-dir ./dump/train/ \
  --dev-dir ./dump/valid/ \
  --outdir ./exp/train.melgan.v1/ \
  --config conf/melgan.v1.yaml \
  --use-norm 1
  --mixed_precision 0 \
  --resume "" > log.melgan.v1.txt 2>&1
```

## Finetune Tacotron-2 with ljspeech pretrained on other languages
Just load pretrained model and training from scratch with other languages.

## Results
Here is a result of melgan based on this config [`melgan.v1.yaml`](https://github.com/dathudeptrai/TensorflowTTS/blob/melgan-example/examples/melgan/conf/melgan.v1.yaml)

### Learning curves
<img src="fig/tensorboard.png" height="500">

### Audio samples
You can hear some audio samples at [`audios`](https://github.com/dathudeptrai/TensorflowTTS/tree/melgan-example/examples/melgan/audios). These audios are generated by ground-truth mel-spectrogram and Melgan at 2M steps.

## Some important notes
	
* This implementation use guided attention by default to help a model learn diagonal alignment faster.
* GMM attention also supported but i haven't test it yet.
* Mish activation function.
* Support window masking for inference, solve problem with very long sentences.
* 50K steps is enough to get a best checkpoint.
* Scheduled teacher forcing is supported but training with teacher forcing give a best performance based on my experiments. You need to be aware of the importance of applying high dropout for prenet (both training and inference), this will reduce the effect of prev mel, so in an inference stage, a noise of prev mel prediction won't affect too much to a current decoder.
* If an amplitude levels of synthesis audio is lower compared to original speech, you may need multiply mel predicted to global gain constant (eg 1.2).

## Reference

1. https://github.com/Rayhane-mamah/Tacotron-2
2. https://github.com/mozilla/TTS
3. https://github.com/tensorflow/addons
4. https://github.com/espnet/espnet
5. [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884)
6. [Generating Sequences With Recurrent Neural Networks](https://arxiv.org/abs/1308.0850)