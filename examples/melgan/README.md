# MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis
Based on the script [`train_melgan.py`](https://github.com/dathudeptrai/TensorflowTTS/blob/melgan-example/examples/melgan/train_melgan.py).

## Training MelGAN from scratch with LJSpeech dataset.
This example code show you how to train MelGAN from scratch with Tensorflow 2 based on custom training loop and tf.function. The data used for this example is LJSpeech, you can download the dataset at  [link](https://keithito.com/LJ-Speech-Dataset/).

### Step 1: Create Tensorflow based Dataloader (tf.dataset)
First, you need define data loader based on AbstractDataset class (see [`abstract_dataset.py`](https://github.com/dathudeptrai/TensorflowTTS/blob/tacotron-2-example/tensorflow_tts/datasets/abstract_dataset.py)). On this example, a dataloader read dataset from path. I use suffix to classify what file is a audio and mel-spectrogram (see [`audio_mel_dataset.py`](https://github.com/dathudeptrai/TensorflowTTS/blob/melgan-example/examples/melgan/audio_mel_dataset.py)). If you already have preprocessed version of your target dataset, you don't need to use this example dataloader, you just need refer my dataloader and modify **generator function** to adapt with your case. Normally, a generator function should return [audio, mel].

### Step 2: Training from scratch
After you redefine your dataloader, pls modify an input arguments, train_dataset and valid_dataset from [`train_melgan.py`](https://github.com/dathudeptrai/TensorflowTTS/blob/melgan-example/examples/melgan/train_melgan.py). Here is an example command line to training tacotron-2 from scratch:

```bash
CUDA_VISIBLE_DEVICES=0 nohup python train_melgan.py \
  --train-dir ./dump/train/ \
  --dev-dir ./dump/valid/ \
  --outdir ./exp/train.melgan.v1/ \
  --config conf/melgan.v1.yaml \
  --use-norm 1
  --mixed_precision 0 \
  --resume "" > log.melgan.v1.txt 2>&1
```

## Finetune Tacotron-2 with ljspeech pretrained on other languages
Just load pretrained model and training from scratch with other languages.

## Results
Here is a result of melgan based on this config [`melgan.v1.yaml`](https://github.com/dathudeptrai/TensorflowTTS/blob/melgan-example/examples/melgan/conf/melgan.v1.yaml)

### Learning curves
<img src="fig/tensorboard.png" height="500">

### Audio samples
You can hear some audio samples at [`audios`](https://github.com/dathudeptrai/TensorflowTTS/tree/melgan-example/examples/melgan/audios). These audios are generated by ground-truth mel-spectrogram and Melgan at 2M steps.

## Some important notes
	
* We don't need use learning rate decay for melgan.
* A weight-norm tensorflow based layer have many problem about ability to save graph, multi-gpu and convergence problem, i will investigate a solution but at this time, pls set is_weight_norm is False on config.
* After one step generator, **DO NOT FORGET** re-generate y_hat for discriminator training.

## Reference

1. https://github.com/descriptinc/melgan-neurips
2. https://github.com/kan-bayashi/ParallelWaveGAN
3. https://github.com/tensorflow/addons
4. [MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis](https://arxiv.org/abs/1910.06711)